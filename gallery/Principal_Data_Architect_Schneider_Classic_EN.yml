locale:
  language: en

layouts:
  - engine: latex
    sections:
      aliases:
        basics: Basics
        education: Education
        work: Work Experience
        projects: Projects
        certificates: Certificates
        skills: Skills
        languages: Languages
        interests: Interests
      order:
        - basics
        - education
        - work
        - skills
        - certificates
        - projects
        - languages
        - interests
    page:
      margins:
        top: 1.5cm
        left: 1.5cm
        right: 1.5cm
        bottom: 1.5cm
      showPageNumbers: true
    template: moderncv-classic
    typography:
      fontSize: 11pt
  - engine: markdown
  - engine: html
    template: calm
    typography:
      fontSize: 16px

content:
  basics:
    name: Wang Zhiwei
    phone: "+86 199 8888 8888"
    email: nocoding188@gmail.com
    url: https://zhiweio.me
    summary: |
      - Senior Data Architect with 7 years of experience designing and delivering scalable cloud-native data platforms and enterprise data warehouses on AWS and Azure.
      - Expertise in building high-throughput real-time streaming (Flink, Kafka) and batch processing (Spark, Databricks) architectures, optimizing data reliability and query performance by 40%+.
      - Proven track record of leading cross-functional teams in digital transformation initiatives, including migrating 10TB+ legacy systems and implementing Master Data Management (MDM) solutions for Fortune 500 clients.

  profiles:
    - network: GitHub
      url: https://github.com/zhiweio
      username: zhiweio

  education:
    - institution: Suzhou University of Science and Technology
      degree: Bachelor
      area: Computer Science and Technology
      startDate: Sep 1, 2015
      endDate: Jul 1, 2019
      summary: |
        - Awarded Third Prize in the 4th National University Cloud Computing Application Innovation Competition (2018).
        - Project: "Implementation of Large-scale Distributed Functional Dependency Mining Algorithm Based on Spark".

  work:
    - name: Cognizant Technology Solutions Shanghai Co. Ltd.
      url: https://www.cognizant.com
      position: Senior Data Engineer (Tech Lead)
      startDate: Dec 2022
      endDate:
      summary: |
        - Led the end-to-end architecture and delivery of a unified Customer Data Platform (CDP) on AWS, integrating 8+ disparate systems (Salesforce, Databricks) to create a "Single Source of Truth" for marketing analytics.
        - Spearheaded the strategic migration of a 10TB+ legacy SQL Server data warehouse to Amazon Redshift, reducing query latency by 40% and infrastructure costs by 25% through serverless orchestration.
        - Architected a Retail Master Data Management (MDM) system using Azure Power Platform and Cosmos DB, enforcing data governance and reducing master data discrepancies by 95% for enterprise operations.
        - Mentored a team of engineers on cloud-native best practices (IaC, CI/CD), fostering engineering excellence and ensuring 99.9% platform uptime.
      keywords:
        - "AWS"
        - "Azure"
        - "Solution Architecture"
        - "Team Leadership"
        - "Data Governance"
    - name: Patsnap Information Technology (Suzhou) Co. Ltd.
      url: https://www.patsnap.com
      position: Data Engineer (Core Big Data Developer)
      startDate: Jun 2021
      endDate: Nov 2022
      summary: |
        - Architected a real-time data warehouse solution for the TFFI SaaS platform using Flink, Kafka, and TiDB, enabling minute-level insights for 180 million global patent records.
        - Designed a custom Spark Diff engine to handle daily synchronization of 500 million analysis records, optimizing incremental updates and reducing database load significantly.
        - Led the technical delivery of localized data systems for 10+ major banking clients (e.g., Agricultural Bank of China), automating deployment pipelines to reduce delivery costs.
      keywords:
        - "Real-time Data Warehouse"
        - "Flink"
        - "TiDB"
        - "Spark"
        - "Client Delivery"
    - name: Intsig Information Co., Ltd.
      url: https://www.intsig.com
      position: Data Engineer
      startDate: Jun 2019
      endDate: Jun 2021
      summary: |
        - Architected high-throughput ETL pipelines processing 100 billion data points for Qixinbao, ensuring sub-second data freshness for 230 million enterprise entities.
        - Modernized the DevOps infrastructure by migrating to GitLab CI/CD, automating testing and deployment to reduce release cycles from hours to minutes.
        - Developed Python-based productivity tools to standardize ETL logic across 1000+ dimensions, reducing boilerplate code by 90%.
      keywords:
        - "ETL Optimization"
        - "Python"
        - "DevOps"
        - "High-throughput Systems"

  skills:
    - name: Data Architecture & Cloud
      level: Expert
      keywords:
        - "AWS (Redshift, Glue, EMR)"
        - "Azure (Synapse, Cosmos DB)"
        - "Data Warehouse (Snowflake, TiDB)"
        - "Terraform (IaC)"
        - "Master Data Management (MDM)"
    - name: Big Data & Streaming
      level: Expert
      keywords:
        - "Apache Spark (Databricks)"
        - "Apache Flink"
        - "Kafka"
        - "Hadoop Ecosystem"
        - "Real-time Data Processing"
    - name: Software Engineering & DevOps
      level: Advanced
      keywords:
        - "Python"
        - "SQL & NoSQL"
        - "CI/CD (GitLab, GitHub Actions)"
        - "Docker & Kubernetes"
        - "Serverless Architecture"
    - name: Leadership & Soft Skills
      level: Advanced
      keywords:
        - "Solution Architecture Design"
        - "Cross-functional Collaboration"
        - "Project Management"
        - "Stakeholder Communication"
        - "Agile Methodologies"

  certificates:
    - name: AWS Certified Data Analytics â€“ Specialty
      url: ""
      issuer: "AWS"
      date: "Jan, 2024"
    - name: AWS Certified Developer - Associate
      url:
      issuer: "AWS"
      date: "Sep, 2024"
    - name: Microsoft Certified Azure Data Engineer Associate
      url:
      issuer: "Microsoft"
      date: "Jun, 2024"
    - name: Databricks Certified Data Engineer Associate
      url:
      issuer: "Databricks"
      date: "Mar, 2023"
    - name: PingCAP Certified TiDB Professional
      url:
      issuer: "PingCAP"
      date: "Mar, 2022"

  projects:
    - name: Bayer Customer Data Platform (CDP)
      url:
      description: Unified cloud-native data platform integrating fragmented customer data for advanced analytics.
      startDate: Dec 2022
      endDate:
      summary: |
        - Architected a serverless data lakehouse on AWS using Glue, Lambda, and Step Functions, optimizing compute costs by 40% while handling billions of daily records.
        - Engineered a custom high-throughput Salesforce integration layer to overcome API limits, synchronizing 10M+ records daily with improved reliability.
        - Implemented comprehensive CI/CD pipelines via GitHub Actions and Terraform (IaC), reducing deployment time by 60% and ensuring zero configuration drift.
      keywords:
        - "AWS Architecture"
        - "Data Lakehouse"
        - "Terraform"
        - "Salesforce Integration"
    - name: Retail Master Data Management Platform
      url:
      description: Enterprise MDM solution on Azure to centralize and govern retail data assets.
      startDate: May 2025
      endDate: Dec 2025
      summary: |
        - Designed a billion-scale data storage architecture using Azure Cosmos DB and Blob Storage, achieving 30x performance gains in bulk data ingestion.
        - Established a cross-cloud data synchronization bridge between Azure operational systems and AWS analytical warehouses using Synapse Link.
        - Enforced Zero Trust security models and automated data quality checks, streamlining data stewardship and saving 20+ operational hours weekly.
      keywords:
        - "Azure Architecture"
        - "Master Data Management"
        - "Cosmos DB"
        - "Data Governance"
    - name: Enterprise Data Warehouse Migration to AWS
      url:
      description: Strategic migration of 10TB+ legacy warehouse to cloud-native Amazon Redshift.
      startDate: Nov 2022
      endDate: May 2023
      summary: |
        - Architected a self-healing, event-driven migration pipeline using AWS Step Functions, automating the transfer of 3,000+ tables with 99% accuracy.
        - Developed a proprietary Python migration engine with AST parsing to automate DDL translation, reducing engineering overhead by 80%.
        - Optimized Redshift schema design with columnar compression, reducing storage footprint by 40% and improving analytical query performance by 5x.
      keywords:
        - "Cloud Migration"
        - "Amazon Redshift"
        - "Python Automation"
        - "Performance Tuning"
